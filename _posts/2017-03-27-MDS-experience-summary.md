---
layout: post
project: true
title: Coursework in Master of Data Science program
description: Mini-projects and assignments I did in machine learning, statistics, programming, and related topics as part of my coursework in the Master of Data Science program.
comments: true
---
## Machine learning

-	Classified handwritten digits using convolutional neural networks, with Keras (Tensorflow backend) and EC2 on Amazon Web Services.
-	Made recommender systems using collaborative filtering, linear, and hybrid models, using sklearn.
-	Used forward selection, backward selection, and recursive feature elimination to identify relevant variables from among hundreds, using sklearn and bestglm (R).
-	Used regularization, model averaging, and Bayesian methods to prevent overfitting.
-	Implemented k-means, k-means++, and k-medoids for clustering unlabelled datasets, using R.
-	Implemented the expectation-maximization algorithm for created mixed models, using R.
-	Used cross-validation to select among multiple models, using sklearn.
-	Compressed, reconstructed, and clustered images of faces using principal-component analysis, using R and sklearn.## Statistics

-	Fit and interpreted linear models, mixed effects models, generalized linear models, generalized additive models, LOESS models, splines, and robust models.-	Used multiple imputation to deal with missing data.-	Used Markov-Chain Monte Carlo (MCMC) for Bayesian models of baseball playersâ€™ batting averages, using rjags (R).-	Performed classical hypothesis tests, exact tests, and permutation tests on many datasets.-	Applied Bonferroni and Benjamini-Hochberg corrections to account for multiple comparisons.-	Decomposed and analysed time series data.## Programming
-	Built and automated the testing of R and Python packages, with continuous integration, using TravisCI, pytest (Python), and testthat (R).-	Used dynamic programming to write a seam-carving algorithm for image dimension reduction.-	Implemented standard searches of lists and graphs (insertion, binary, merge, depth-first, breadth-first).-	Analyzed time and space complexity of simple algorithms.
-	Wrote and used objects and classes in Python and R.## Data visualization
-	Created interactive shiny apps to explore different encodings and subsets of US crime data from 1975-2015.-	Created static visualizations of network data (arcplots, network graphs, adjacency matrices), such as Twitter hashtag networks and character networks in Jane Austen novels. -	Created static visualizations of spatial data (choropleth maps, dot maps), such as crime rates in Vancouver and earthquakes across the west coast of North America.## Web and cloud computing
-	Scraped data from static web-pages.-	Conducted analysis of data queried from the Twitter API, using tweepy (Python) and twitteR (R).-	Analysed historical word frequencies in the Google n-grams dataset, using Simple Storage Service (S3) and Elastic Map Reduce (EMR) on Amazon Web Services.## Databases-	Queried from SQL databases.-	Designed SQL schemas.-	Queried from XML databases, using Xpath.-	Applied k-anonymity and l-diversity to protect against privacy threats.## Data wrangling
-	Used dplyr to manipulate dataframes, using window functions, grouping functions, and mutations.-	Converted character representations of date-times into POSIX date-times.-	Used standard joins (inner join, left join, full join, etc) to combine datasets with common variable.-	Converted JSON and XML data to R lists to enable targeted queries.